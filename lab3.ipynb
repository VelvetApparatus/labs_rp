{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "717ada11",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install faster-whisper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "750a5a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "from faster_whisper import WhisperModel\n",
    "model_size = \"large-v3\"\n",
    "\n",
    "# Run on GPU with FP16\n",
    "gaam_model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "\n",
    "# or run on GPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cuda\", compute_type=\"int8_float16\")\n",
    "# or run on CPU with INT8\n",
    "# model = WhisperModel(model_size, device=\"cpu\", compute_type=\"int8\")\n",
    "\n",
    "segments, info = gaam_model.transcribe(\"audio.mp3\", beam_size=5)\n",
    "\n",
    "print(\"Detected language '%s' with probability %f\" % (info.language, info.language_probability))\n",
    "\n",
    "for segment in segments:\n",
    "    print(\"[%.2fs -> %.2fs] %s\" % (segment.start, segment.end, segment.text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e03fc3a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install vosk soundfile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55b68c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import subprocess\n",
    "import os\n",
    "\n",
    "def transcribe_vosk(audio_path):\n",
    "    \"\"\"Транскрипция с помощью Vosk через командную строку\"\"\"\n",
    "    output_file = \"temp_vosk_output.txt\"\n",
    "    \n",
    "    # Запускаем vosk-transcriber как в примере\n",
    "    start_time = time.time()\n",
    "    result = subprocess.run([\n",
    "        'vosk-transcriber', \n",
    "        '-l', 'ru', \n",
    "        '-i', audio_path, \n",
    "        '-o', output_file\n",
    "    ], capture_output=True, text=True)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Читаем результат\n",
    "    try:\n",
    "        with open(output_file, 'r', encoding='utf-8') as f:\n",
    "            text = f.read().strip()\n",
    "        times = end_time - start_time\n",
    "        # Удаляем временный файл\n",
    "        os.remove(output_file)\n",
    "        return text, times\n",
    "    except FileNotFoundError:\n",
    "        print(f\"Vosk output file not found for {audio_path}\")\n",
    "        return \"\"\n",
    "\n",
    "transcribe_vosk('dataset/1.mp3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f6764c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "146f224e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModel\n",
    "\n",
    "revision = \"e2e_rnnt\"  # can be any v3 model: ssl, ctc, rnnt, e2e_ctc, e2e_rnnt\n",
    "gaam_model = AutoModel.from_pretrained(\n",
    "    \"ai-sage/GigaAM-v3\",\n",
    "    revision=revision,\n",
    "    trust_remote_code=True,\n",
    ")\n",
    "\n",
    "transcription = gaam_model.transcribe(\"example.wav\")\n",
    "\n",
    "transcription()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1bc93e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install pydub jiwer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b5be8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import wave\n",
    "import json\n",
    "from pydub import AudioSegment\n",
    "import io\n",
    "from jiwer import wer, cer\n",
    "import string\n",
    "\n",
    "whisper_model = WhisperModel(model_size, device=\"cuda\", compute_type=\"float16\")\n",
    "gigaam_model = gaam_model\n",
    "\n",
    "def preprocess_text(text):\n",
    "    \"\"\"Предобработка текста для расчета метрик\"\"\"\n",
    "    text = text.lower()\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    return text.strip()\n",
    "\n",
    "def transcribe_whisper(audio_paths, prompt=None):\n",
    "    transcripts = []\n",
    "    times = []\n",
    "    \n",
    "    for audio_path in audio_paths:\n",
    "        start_time = time.time()\n",
    "        \n",
    "        if prompt:\n",
    "            segments, info = whisper_model.transcribe(audio_path, beam_size=5, initial_prompt=prompt, condition_on_previous_text=False )\n",
    "        else:\n",
    "            segments, info = whisper_model.transcribe(audio_path, beam_size=5)\n",
    "        \n",
    "        text = ' '.join([segment.text for segment in segments])\n",
    "        end_time = time.time()\n",
    "        \n",
    "        transcripts.append(text)\n",
    "        times.append(end_time - start_time)\n",
    "    \n",
    "    return transcripts, times\n",
    "\n",
    "def transcribe_vosk(audio_paths):\n",
    "    transcripts = []\n",
    "    times = []\n",
    "    \n",
    "    for audio_path in audio_paths:\n",
    "\n",
    "        output_file = \"temp_vosk_output.txt\"\n",
    "        \n",
    "        # Запускаем vosk-transcriber как в примере\n",
    "        start_time = time.time()\n",
    "        result = subprocess.run([\n",
    "            'vosk-transcriber', \n",
    "            '-l', 'ru', \n",
    "            '-i', audio_path, \n",
    "            '-o', output_file\n",
    "        ], capture_output=True, text=True)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        # Читаем результат\n",
    "        try:\n",
    "            with open(output_file, 'r', encoding='utf-8') as f:\n",
    "                text = f.read().strip()\n",
    "            time1 = end_time - start_time\n",
    "            # Удаляем временный файл\n",
    "            os.remove(output_file)\n",
    "        except FileNotFoundError:\n",
    "            print(f\"Vosk output file not found for {audio_path}\")\n",
    "            return \"\"   \n",
    "        transcripts.append(text)\n",
    "        times.append(time1)\n",
    "    \n",
    "    return transcripts, times\n",
    "\n",
    "def transcribe_gigaam(audio_paths):\n",
    "    transcripts = []\n",
    "    times = []\n",
    "    \n",
    "    for audio_path in audio_paths:\n",
    "        start_time = time.time()\n",
    "        transcription = gigaam_model.transcribe(audio_path)\n",
    "        end_time = time.time()\n",
    "        \n",
    "        transcripts.append(transcription)\n",
    "        times.append(end_time - start_time)\n",
    "    \n",
    "    return transcripts, times\n",
    "\n",
    "def get_audio_duration_sec(audio_path):\n",
    "    audio = AudioSegment.from_file(audio_path)\n",
    "    return len(audio) / 1000.0\n",
    "\n",
    "def evaluate_models():\n",
    "    audio_files = [f\"dataset/{i}.mp3\" for i in range(1, 11)]\n",
    "    \n",
    "    references = []\n",
    "    for i in range(1, 11):\n",
    "        with open(f\"dataset/{i}.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "            references.append(f.read().strip())\n",
    "    \n",
    "    # Получение длительностей аудио\n",
    "    durations = [get_audio_duration_sec(path) for path in audio_files]\n",
    "    \n",
    "    # Транскрипция всеми моделями\n",
    "    print(\"Транскрипция Whisper...\")\n",
    "    whis_results, whis_times = transcribe_whisper(audio_files)\n",
    "    \n",
    "    print(\"Транскрипция Vosk...\")\n",
    "    vosk_results, vosk_times = transcribe_vosk(audio_files)\n",
    "    \n",
    "    print(\"Транскрипция GigaAM...\")\n",
    "    giga_results, giga_times = transcribe_gigaam(audio_files)\n",
    "    \n",
    "    # Предобработка текстов\n",
    "    references_clean = [preprocess_text(ref) for ref in references]\n",
    "    whis_clean = [preprocess_text(text) for text in whis_results]\n",
    "    vosk_clean = [preprocess_text(text) for text in vosk_results]\n",
    "    giga_clean = [preprocess_text(text) for text in giga_results]\n",
    "    \n",
    "    # Расчет метрик\n",
    "    results = {}\n",
    "    \n",
    "    # Whisper\n",
    "    results['whisper'] = {\n",
    "        'wer': wer(references_clean, whis_clean),\n",
    "        'cer': cer(references_clean, whis_clean),\n",
    "        'rtf': [t/d for t, d in zip(whis_times, durations)],\n",
    "        'transcriptions': whis_results\n",
    "    }\n",
    "    \n",
    "    # Vosk\n",
    "    results['vosk'] = {\n",
    "        'wer': wer(references_clean, vosk_clean),\n",
    "        'cer': cer(references_clean, vosk_clean),\n",
    "        'rtf': [t/d for t, d in zip(vosk_times, durations)],\n",
    "        'transcriptions': vosk_results\n",
    "    }\n",
    "    \n",
    "    # GigaAM\n",
    "    results['gigaam'] = {\n",
    "        'wer': wer(references_clean, giga_clean),\n",
    "        'cer': cer(references_clean, giga_clean),\n",
    "        'rtf': [t/d for t, d in zip(giga_times, durations)],\n",
    "        'transcriptions': giga_results\n",
    "    }\n",
    "    \n",
    "    return results, references\n",
    "\n",
    "# Запуск оценки\n",
    "if __name__ == \"__main__\":\n",
    "    results, references = evaluate_models()\n",
    "    \n",
    "    # Вывод результатов\n",
    "    for model_name, metrics in results.items():\n",
    "        avg_rtf = sum(metrics['rtf']) / len(metrics['rtf'])\n",
    "        print(f\"\\n{model_name.upper()}:\")\n",
    "        print(f\"WER: {metrics['wer']:.3f}\")\n",
    "        print(f\"CER: {metrics['cer']:.3f}\")\n",
    "        print(f\"RTF: {avg_rtf:.3f}\")\n",
    "        \n",
    "        # Примеры транскрипций\n",
    "        print(\"Примеры транскрипций:\")\n",
    "        for i, (ref, hyp) in enumerate(zip(references[:10], metrics['transcriptions'][:10])):\n",
    "            print(f\"  {i+1}. Reference: {ref}\")\n",
    "            print(f\"     Pred: {hyp}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
